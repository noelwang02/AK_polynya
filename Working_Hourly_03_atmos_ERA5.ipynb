{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "226b3e75",
   "metadata": {},
   "source": [
    "# 03. Atmospheric maps from ERA5 atmospheric reanalysis\n",
    "Data source:\n",
    "\n",
    "DOI: 10.24381/cds.adbb2d47\n",
    "<br>\n",
    "Dataset is daily and hourly Jan 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03e3b60",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9baa51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import numpy as np, numpy.ma as ma\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# time\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# local system \n",
    "import sys  \n",
    "import glob\n",
    "import os\n",
    "\n",
    "# plotting\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors\n",
    "import cmocean\n",
    "\n",
    "# geo plotting\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeat\n",
    "\n",
    "# for use in suppressing repeated warnings when mapping w/ shapely\n",
    "import shapely\n",
    "import warnings\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning) \n",
    "\n",
    "# path to own functions\n",
    "sys.path.append('../Libraries_functions/')\n",
    "from LIB_ASI_SIC_UniB import grab_ASI_SIC, grab_projinfo_SIC\n",
    "from LIB_geo_func import *\n",
    "from LIB_geo_plot import *\n",
    "\n",
    "\n",
    "# OSI SAF sea ice drift\n",
    "from LIB_OSI_SAF import grab_projinfo_OSISAF, grab_OSISAF_drift\n",
    "\n",
    "# NSIDC sea ice drift\n",
    "from LIB_PPdrift_NSIDC0116 import grab_projinfo_PPdrift\n",
    "\n",
    "# ERA5\n",
    "# from LIB_access_ERA5 import grab_ERA5\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# potentially uninstall pyhdf?\n",
    "\n",
    "# math\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c292f5",
   "metadata": {},
   "source": [
    "### Grab atmos. fields by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "811c93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# specify date to import\n",
    "date = datetime(2024, 1, 1)\n",
    "date_list = pd.date_range(datetime(2024, 1, 1), datetime(2024, 1, 31), freq=\"H\") #make this a date list\n",
    "\n",
    "#============================\n",
    "\n",
    "file_path = f'/Volumes/Seagate2/ERA5_transferred/hourly/ERA5_{date.strftime(\"%Y\")}.nc'\n",
    "\n",
    "ds = xr.load_dataset(file_path)\n",
    "ds.close\n",
    "\n",
    "ds_date = ds.sel(time = date)\n",
    "\n",
    "ERA5 = {}\n",
    "\n",
    "ERA5['time'] = ds_date.time.values\n",
    "ERA5['lon'] = ds_date.longitude.values\n",
    "ERA5['lat'] = ds_date.latitude.values\n",
    "\n",
    "ERA5['lon_grid'], ERA5['lat_grid'] = np.meshgrid(ERA5['lon'], ERA5['lat'])\n",
    "\n",
    "ERA5['u10'] = ds_date.u10.values\n",
    "ERA5['v10'] = ds_date.v10.values\n",
    "ERA5['msl'] = ds_date.msl.values\n",
    "# ERA5['sst'] = ds_date.sst.values\n",
    "\n",
    "#create empty lists\n",
    "u10_average = []\n",
    "v10_average = []\n",
    "t2m_average = []\n",
    "date_axs = [] #guess I didn't actually need this haha\n",
    "sst_average = []\n",
    "\n",
    "uv_daily = []\n",
    "\n",
    "combo_averageuv = []\n",
    "average_combouv = []\n",
    "\n",
    "#averaging the values for a given date. takes average vector for each day.\n",
    "for date in date_list:\n",
    "    #subsetting data\n",
    "    date_axs.append(date.to_pydatetime)\n",
    "    # ds_subset = ds.sel(longitude = slice(-150, -138), latitude = slice(72, 69.5), time = date)\n",
    "    u10_average.append(ds_subset.mean(dim=(\"latitude\", \"longitude\")).u10.values)\n",
    "    # t2m_average.append((ds_subset.mean(dim=(\"latitude\", \"longitude\")).t2m.values)-273.15) #convert to Celsius\n",
    "    v10_average.append((ds_subset.mean(dim=(\"latitude\", \"longitude\")).v10.values))\n",
    "    # sst_average.append((ds_subset.mean(dim=(\"latitude\", \"longitude\")).sst.values))\n",
    "\n",
    "    #triangulating values of uv over a given date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e89db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in SIC projection\n",
    "# read daily sic data from computer files into dictionary\n",
    "data = grab_ASI_SIC(date=datetime(2020,1,1), \n",
    "    main_path='/Volumes/Seagate2/asi-AMSR-SIC/n6250/', \n",
    "    coord_file='LongitudeLatitudeGrid-n6250-Arctic.hdf', \n",
    "    hemisphere='n', resolution='6250', version='v5.4', \n",
    "    return_vars=['proj'], \n",
    "    include_units=False, annual_folders=False, return_dict = True, quiet=True)\n",
    "\n",
    "#making the mask\n",
    "\n",
    "df = pd.read_csv(\"/Users/reu/Box/Data/mask2.csv\")\n",
    "listx2 = df.xlist.values\n",
    "listy2 = df.ylist.values\n",
    "\n",
    "polygon2 = geometry.Polygon([[x, y] for x,y in zip(listx2, listy2)])\n",
    "\n",
    "mask2 = np.full(ERA5['u10'][0].shape, False)\n",
    "\n",
    "for ii in range (mask2.shape[0]):\n",
    "    for jj in range (mask2.shape[1]):\n",
    "        \n",
    "        trans_point = data['proj'].transform_point(ERA5[\"x\"][jj], NSIDC[\"y\"][ii], NSIDC['proj'])\n",
    "        point2 = Point(trans_point)\n",
    "        mask2[ii, jj] = polygon2.contains(point2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1ad28d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9913672        nan]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(u10_average[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(u10_average):\n\u001b[0;32m----> 5\u001b[0m     uv_daily\u001b[38;5;241m.\u001b[39mappend(math\u001b[38;5;241m.\u001b[39msqrt((u10_average[i])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m (v10_average[i])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      6\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < len(u10_average):\n",
    "    uv_daily.append(math.sqrt((u10_average[i])**2 + (v10_average[i])**2))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "594fea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2024-01-01 00:00:00', '2024-01-01 01:00:00',\n",
      "               '2024-01-01 02:00:00', '2024-01-01 03:00:00',\n",
      "               '2024-01-01 04:00:00', '2024-01-01 05:00:00',\n",
      "               '2024-01-01 06:00:00', '2024-01-01 07:00:00',\n",
      "               '2024-01-01 08:00:00', '2024-01-01 09:00:00',\n",
      "               ...\n",
      "               '2024-01-30 15:00:00', '2024-01-30 16:00:00',\n",
      "               '2024-01-30 17:00:00', '2024-01-30 18:00:00',\n",
      "               '2024-01-30 19:00:00', '2024-01-30 20:00:00',\n",
      "               '2024-01-30 21:00:00', '2024-01-30 22:00:00',\n",
      "               '2024-01-30 23:00:00', '2024-01-31 00:00:00'],\n",
      "              dtype='datetime64[ns]', length=721, freq='H')\n",
      "721\n",
      "721\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(date_list)\n",
    "print(len(date_list))\n",
    "print(len(u10_average))\n",
    "print(len(uv_daily))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b725c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I think this was trying to get denom of directional constantcy\n",
    "\n",
    "print(ds_subset.u10.values.shape)\n",
    "\n",
    "for date in date_list:\n",
    "    date_axs.append(date.to_pydatetime)\n",
    "    i = 0\n",
    "    while i < len(ds_subset.u10.values):\n",
    "        uv_daily.append(math.sqrt((ds_subset.u10.values[i])**2 + (ds_subset.v10.values[i])**2))\n",
    "        i += 1\n",
    "\n",
    "print(ds_subset.u10.values.shape)\n",
    "\n",
    "print(f'uv_daily is: {uv_daily}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd0d1ae",
   "metadata": {},
   "source": [
    "### Plotting time series of wind speed, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting\n",
    "x = date_list\n",
    "y = uv_daily #determine what to plot\n",
    "fig, ax = plt.subplots(figsize = (20, 5))\n",
    "plt.plot(x, y)\n",
    "\n",
    "#formatting the plot\n",
    "plt.xticks(rotation=30)\n",
    "plt.xticks(date_list[::24])\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%d'))\n",
    "#labels\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('uv wind (m/s)')\n",
    "\n",
    "plt.title(f'Average hourly uv wind from {date_list[0].strftime(\"%d-%b-%Y\")} to {date_list[-1].strftime(\"%d-%b-%Y\")} over polynya (coordinates v2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49cd9a4",
   "metadata": {},
   "source": [
    "## stick plot of vector directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27067e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stick plot\n",
    "#starts an array\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (20, 5))\n",
    "qv = plt.quiver(date_list, np.zeros_like(date_list), u10_average, v10_average, width=0.003)\n",
    "qk = ax.quiverkey(qv, 10, 10, 5, r'$20 \\frac{km}{day}$',labelpos='E' )\n",
    "\n",
    "#why is it not showing up!\n",
    "\n",
    "# save figure, if desired\n",
    "save_path = f'/Users/reu/Desktop/quiver.png'\n",
    "fig.savefig(save_path, dpi=300, bbox_inches = 'tight')\n",
    "\n",
    "#formatting the plot\n",
    "plt.xticks(rotation=30)\n",
    "plt.xticks(date_list)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%d'))\n",
    "plt.yticks([])\n",
    "#labels\n",
    "plt.xlabel('Date')\n",
    "#ax.axvspan(datetime(2024, 1, 10), datetime(2024, 1, 15), facecolor='silver', alpha=0.5)\n",
    "\n",
    "plt.title(f'u-v wind {date_list[0].strftime(\"%d-%b-%Y\")} to {date_list[-1].strftime(\"%d-%b-%Y\")} over polynya (v2 coordinates)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a347a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b76ea7b-a95f-48bf-b8e8-a2d0f3d384f4",
   "metadata": {},
   "source": [
    "## Make map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab1801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# specify date to plot SIC\n",
    "#============================\n",
    "date_list = pd.date_range(datetime(2004, 1, 1), datetime(2023, 1, 31)) #make this a date list\n",
    "#============================\n",
    "\n",
    "\n",
    "for date in date_list:\n",
    "        \n",
    "        #grabbing ERA5 data\n",
    "        file_path = '/Volumes/Seagate2/Jan2024ERA5.nc'\n",
    "\n",
    "        ds = xr.load_dataset(file_path)\n",
    "        ds.close\n",
    "\n",
    "        ds_date = ds.sel(time = slice(date, date + timedelta(hours=23))).mean(dim=\"time\")\n",
    "        #takes daily average of time slice\n",
    "\n",
    "        ERA5 = {}\n",
    "\n",
    "        #ERA5['time'] = ds_date.time.values\n",
    "        ERA5['lon'] = ds_date.longitude.values\n",
    "        ERA5['lat'] = ds_date.latitude.values\n",
    "\n",
    "        ERA5['lon_grid'], ERA5['lat_grid'] = np.meshgrid(ERA5['lon'], ERA5['lat'])\n",
    "\n",
    "        ERA5['u10'] = ds_date.u10.values\n",
    "        ERA5['v10'] = ds_date.v10.values\n",
    "        ERA5['msl'] = ds_date.msl.values\n",
    "        \n",
    "        # read daily sic data from computer files into dictionary\n",
    "        data = grab_ASI_SIC(date=date, \n",
    "                        main_path='/Volumes/Seagate2/asi-AMSR-SIC/n6250/', \n",
    "                        coord_file='LongitudeLatitudeGrid-n6250-Arctic.hdf', \n",
    "                        hemisphere='n', resolution='6250', version='v5.4', \n",
    "                        return_vars=['xx', 'yy', 'lon', 'lat', 'sic', 'proj', 'ds'], \n",
    "                        include_units=False, annual_folders=False, return_dict = True, quiet=True)\n",
    "\n",
    "        # create figure\n",
    "        #--------------\n",
    "        # create map figure in north polar stereographic projection\n",
    "        map_projection = ccrs.NorthPolarStereo(central_longitude=205)\n",
    "        fig, ax = plt.subplots(figsize=(8,8), subplot_kw=dict(projection=map_projection))\n",
    "\n",
    "        # background color\n",
    "        ax.patch.set_facecolor('lightgray')\n",
    "\n",
    "        # set map extent [lon1, lon2, lat1, lat2]\n",
    "        ax.set_extent([200, 230, 68, 74], crs=ccrs.PlateCarree())  \n",
    "\n",
    "        # add coastlines\n",
    "        ax.coastlines(zorder=100)\n",
    "\n",
    "        # add land\n",
    "        add_land(ax, scale='50m', color='lightgray', alpha=1, fill_dateline_gap=True, zorder=5)\n",
    "\n",
    "        # lat / lon lines\n",
    "        add_grid(ax, lats=np.arange(60,90,10), lons=np.arange(0,360,90), linewidth=1, color='gray', alpha=0.5, zorder=4)\n",
    "\n",
    "        # plot 2d sic data \n",
    "        icec = ax.pcolormesh(data['xx'], data['yy'], data['sic'], \n",
    "                                cmap = cmocean.cm.ice, vmin=0, vmax=100, transform=data['proj'])\n",
    "\n",
    "        #color bar\n",
    "        plt.colorbar(icec, label='SIC (%)', orientation='horizontal', shrink = 0.25, pad=0.025)\n",
    "\n",
    "        # label date\n",
    "        ax.text(0, 1, date.strftime('%Y-%B-%d'), ha='left', va='bottom', transform=ax.transAxes, clip_on=False)\n",
    "\n",
    "        # ERA5 10m wind field\n",
    "        qv1 = ax.quiver(ERA5['lon_grid'], ERA5['lat_grid'], *fix_cartopy_vectors(ERA5['u10'], ERA5['v10'], ERA5['lat_grid']), \n",
    "                        regrid_shape = 15, color = 'gray', width = 0.002, headwidth=5, scale = 500, transform = ccrs.PlateCarree(), zorder=5)\n",
    "        qk = ax.quiverkey(qv1, 0.8, -0.1, 10, r'$10 \\frac{m}{s}$ wind', labelpos='E',transform=ccrs.PlateCarree())\n",
    "\n",
    "        # ERA5 mean sea level pressure\n",
    "        line_c = ax.contour(ERA5['lon_grid'], ERA5['lat_grid'], ERA5['msl']/100, \n",
    "                levels = np.arange(960,1080,4), colors='k', transform = ccrs.PlateCarree(), zorder=5)\n",
    "\n",
    "        # Use the line contours to place contour labels.\n",
    "        ax.clabel(line_c,  # Typically best results when labelling line contours.\n",
    "                colors=['black'],\n",
    "                manual=False,  # Automatic placement vs manual placement.\n",
    "                inline=True,  # Cut the line where the label will be placed.\n",
    "                fmt=' {:.0f} '.format,  # Labes as integers, with some extra space.\n",
    "                zorder=4\n",
    "                )\n",
    "\n",
    "        ax.plot([0.1,0.2], [-0.05, -0.05], clip_on=False, c='k', transform=ax.transAxes)\n",
    "        ax.text(0.05, -0.1, 'sea level pressure (hPa)', c='k', transform=ax.transAxes)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        # # save figure, if desired\n",
    "        # save_path = f'/Users/reu/Box/Maps/SIC_maps/{date.strftime(\"%b%Y\")}/cropped_map_{date.strftime(\"%Y-%m-%d\")}.png'\n",
    "        # fig.savefig(save_path, dpi=300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ee2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.u10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e45ba",
   "metadata": {},
   "source": [
    "### Importing data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutting off January 31st\n",
    "short_list = []\n",
    "short_u10_average = []\n",
    "short_t2m_average = []\n",
    "short_v10_average = []\n",
    "i = 0\n",
    "\n",
    "while i < 30:\n",
    "    short_list.append(date_list[i])\n",
    "    short_v10_average.append(v10_average[i])\n",
    "    short_u10_average.append(u10_average[i])\n",
    "    short_t2m_average.append(t2m_average[i])\n",
    "    i = i + 1\n",
    "\n",
    "print(f'short_list: {len(short_list)}. u10_average: {len(short_u10_average)}. t2m_average: {len(short_t2m_average)}. v10_average: {len(short_v10_average)}')\n",
    "\n",
    "\n",
    "#exporting data as csv\n",
    "d = {'time': date_list, 'u10_average(m/s)': u10_average, 't2m_average(m/s)': t2m_average, 'v10_average(m/s)': v10_average, 'uv_wind': uv_daily}\n",
    "df2 = pd.DataFrame(data=d)\n",
    "df2.to_csv('/Users/reu/Box/Data/hourly_speeds_wind_v2.csv', index=None) #removes Index column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b273a7a3",
   "metadata": {},
   "source": [
    "### Plotting all the variables on one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b8e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, ax4 = plt.subplots(figsize=(20,5))\n",
    "\n",
    "plt.plot(df.time, df2.u10_average, label='u10_average')\n",
    "plt.plot(df.time, df2.v10_average, label = 'v10_average')\n",
    "plt.plot(df.time, df.speed_of_mean, label = 'magnitude of mean ice drift vector')\n",
    "plt.plot(df.time, df.mean_of_speed, label = 'mean magnitude of ice drift vectors')\n",
    "\n",
    "ax4.legend()\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "plt.title(f'Wind and Drift from {date_list[0].strftime(\"%d-%b-%Y\")} to {date_list[-1].strftime(\"%d-%b-%Y\")} over polynya')\n",
    "\n",
    "df2.time.shape\n",
    "df2.u10_average.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba56fa93",
   "metadata": {},
   "source": [
    "## drift/wind ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80bb04b",
   "metadata": {},
   "source": [
    "### Wind speed (combined u-v component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845bbc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining the u-v components with MATH\n",
    "\n",
    "uv_wind = []\n",
    "i = 0\n",
    "while i < len(short_u10_average):\n",
    "    uv_wind.append(math.sqrt(short_u10_average[i]**2 + short_v10_average[i]**2))\n",
    "    i = i + 1\n",
    "\n",
    "print(uv_wind)\n",
    "print(type(uv_wind))\n",
    "print(len(uv_wind))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10916211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting uv-wind vs. time\n",
    "\n",
    "fig5, ax5 = plt.subplots(figsize=(20,5))\n",
    "\n",
    "plt.plot(df.time, uv_wind, label='uv_wind')\n",
    "# plt.plot(df.time, df2.v10_average, label = 'v10_average')\n",
    "# plt.plot(df.time, df.speed_of_mean, label = 'magnitude of mean ice drift vector')\n",
    "# plt.plot(df.time, df.mean_of_speed, label = 'mean magnitude of ice drift vectors')\n",
    "\n",
    "ax5.legend()\n",
    "\n",
    "plt.xticks(rotation=30)\n",
    "plt.title(f'u-v wind from {date_list[0].strftime(\"%d-%b-%Y\")} to {date_list[-1].strftime(\"%d-%b-%Y\")} over polynya')\n",
    "\n",
    "df2.time.shape\n",
    "df2.u10_average.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e46ab5",
   "metadata": {},
   "source": [
    "### calculating wind factor ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6453524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reimports the uv-wind :)\n",
    "d = {'time': short_list, 'u10_average': short_u10_average, 't2m_average': short_t2m_average, 'v10_average': short_v10_average, 'uv_wind': uv_wind}\n",
    "df2 = pd.DataFrame(data=d)\n",
    "df2.to_csv('./Data/speeds_wind.csv', index=None) #removes Index column\n",
    "df2 = pd.read_csv('./Data/speeds_wind.csv')\n",
    "df2['time'] = pd.to_datetime(df2.time)\n",
    "\n",
    "\n",
    "df = pd.read_csv('./Data/speeds_ice.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3097e1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b74336e1",
   "metadata": {},
   "source": [
    "## calculating wind factor ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9934acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_ratio_mean_of_speed = []\n",
    "drift_ratio_speed_of_mean = []\n",
    "i = 0\n",
    "while i < len(df.mean_of_speed):\n",
    "    drift_ratio_mean_of_speed.append(df.mean_of_speed[i] / uv_wind[i])\n",
    "    drift_ratio_speed_of_mean.append(df.speed_of_mean[i]/ uv_wind[i])\n",
    "    i +=1 \n",
    "\n",
    "#plotting drift ratios\n",
    "\n",
    "fig6, ax6 = plt.subplots(figsize=(20,5))\n",
    "\n",
    "plt.plot(df.time, drift_ratio_mean_of_speed, label = 'magnitude of mean ice drift vector / uv_wind')\n",
    "\n",
    "ax6.legend()\n",
    "plt.xticks(rotation=30)\n",
    "plt.title(f'Drift ratios from {date_list[0].strftime(\"%d-%b-%Y\")} to {date_list[-1].strftime(\"%d-%b-%Y\")} over polynya')\n",
    "ax6.xaxis.set_major_formatter(mdates.DateFormatter('%b-%d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9a6ba3",
   "metadata": {},
   "source": [
    "## Directional constantcy of wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c4035",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_constantcy = []\n",
    "i = 0\n",
    "while i < len(drift_ratio_mean_of_speed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AK_polynya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
